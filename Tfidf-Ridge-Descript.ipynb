{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:\n",
      " ['periods_test.csv', 'train_08_features.csv.gz', 'test.csv', 'train.csv.zip', 'test_active.csv.zip', 'periods_test.csv.zip', 'test_02.csv', 'test_jpg.zip', 'test_features.csv', 'train_08.csv', 'train_active.csv', 'train_active.csv.zip', 'test.csv.zip', 'train.csv', 'train_features.csv', 'periods_train.csv', 'test_active.csv', 'periods_train.csv.zip']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergei/.local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "notebookstart= time.time()\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "print(\"Data:\\n\",os.listdir(\"./input\"))\n",
    "\n",
    "# Models Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Gradient Boosting\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# Tf-Idf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "# Viz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFOLDS = 10\n",
    "SEED = 2018\n",
    "VALID = True\n",
    "NROW =None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None, seed_bool = True):\n",
    "        if(seed_bool == True):\n",
    "            params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "        \n",
    "def get_oof(clf, x_train, y, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        print('\\nFold {}'.format(i))\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
    "    \n",
    "def cleanName(text):\n",
    "    try:\n",
    "        textProc = text.lower()\n",
    "        # textProc = \" \".join(map(str.strip, re.split('(\\d+)',textProc)))\n",
    "        #regex = re.compile(u'[^[:alpha:]]')\n",
    "        #textProc = regex.sub(\" \", textProc)\n",
    "        textProc = re.sub('[!@#$_“”¨«»®´·º½¾¿¡§£₤‘’]', '', textProc)\n",
    "        textProc = \" \".join(textProc.split())\n",
    "        return textProc\n",
    "    except: \n",
    "        return \"name error\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y0):\n",
    "    assert len(y) == len(y0)\n",
    "    return np.sqrt(np.mean(np.power((y - y0), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Load Stage\n",
      "Train shape: 1503424 Rows, 499 Columns\n",
      "Test shape: 508438 Rows, 499 Columns\n",
      "Combine Train and Test\n",
      "\n",
      "All Data shape: 2011862 Rows, 499 Columns\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData Load Stage\")\n",
    "training = pd.read_csv('./input/train_features.csv', index_col = \"item_id\", parse_dates = [\"activation_date\"],\n",
    "                      nrows=NROW)\n",
    "traindex = training.index\n",
    "testing = pd.read_csv('./input/test_features.csv', index_col = \"item_id\", parse_dates = [\"activation_date\"],\n",
    "                     nrows=NROW)\n",
    "testdex = testing.index\n",
    "\n",
    "ntrain = training.shape[0]\n",
    "ntest = testing.shape[0]\n",
    "\n",
    "kf = KFold(ntrain, n_folds=NFOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "y = training.deal_probability.copy()\n",
    "training.drop(\"deal_probability\",axis=1, inplace=True)\n",
    "print('Train shape: {} Rows, {} Columns'.format(*training.shape))\n",
    "print('Test shape: {} Rows, {} Columns'.format(*testing.shape))\n",
    "\n",
    "print(\"Combine Train and Test\")\n",
    "df = pd.concat([training,testing],axis=0)\n",
    "del training, testing\n",
    "gc.collect()\n",
    "print('\\nAll Data shape: {} Rows, {} Columns'.format(*df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Validation Index and Remove Dead Variables\n",
    "training_index = df.loc[df.activation_date<=pd.to_datetime('2017-04-07')].index\n",
    "validation_index = df.loc[df.activation_date>=pd.to_datetime('2017-04-08')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TF-IDF] Term Frequency Inverse Document Frequency Stage\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering \n",
    "\n",
    "# Meta Text Features\n",
    "textfeats = [\"description\", \"title\"]\n",
    "\n",
    "df['title'] = df['title'].apply(lambda x: cleanName(x))\n",
    "df[\"description\"]   = df[\"description\"].apply(lambda x: cleanName(x))\n",
    "\n",
    "print(\"\\n[TF-IDF] Term Frequency Inverse Document Frequency Stage\")\n",
    "russian_stop = set(stopwords.words('russian'))\n",
    "\n",
    "tfidf_para = {\n",
    "    \"stop_words\": russian_stop,\n",
    "    \"analyzer\": 'word',\n",
    "    \"token_pattern\": r'\\w{1,}',\n",
    "    \"sublinear_tf\": True,\n",
    "    \"dtype\": np.float32,\n",
    "    \"norm\": 'l2',\n",
    "    #\"min_df\":5,\n",
    "    #\"max_df\":.9,\n",
    "    \"smooth_idf\":False\n",
    "}\n",
    "\n",
    "\n",
    "def get_col(col_name): return lambda x: x[col_name]\n",
    "##I added to the max_features of the description. It did not change my score much but it may be worth investigating\n",
    "vectorizer = FeatureUnion([\n",
    "        ('description',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=17000,\n",
    "            **tfidf_para,\n",
    "            preprocessor=get_col('description'))),\n",
    "        ('title',CountVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words = russian_stop,\n",
    "            #max_features=7000,\n",
    "            preprocessor=get_col('title')))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2011862 entries, b912c3c6a6ad to d374d332992f\n",
      "Columns: 499 entries, activation_date to param_1_copy_desc_len_ratio\n",
      "dtypes: bool(1), datetime64[ns](1), float64(402), int64(33), object(62)\n",
      "memory usage: 7.6+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    if df[i].dtypes=='float64':\n",
    "        df[i] = df[i].astype('float16')\n",
    "    elif df[i].dtypes=='object':\n",
    "        df[i] = df[i].astype('category')\n",
    "    elif df[i].dtypes=='int64':\n",
    "        df[i] = df[i].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2011862 entries, b912c3c6a6ad to d374d332992f\n",
      "Columns: 499 entries, activation_date to param_1_copy_desc_len_ratio\n",
      "dtypes: bool(1), category(62), datetime64[ns](1), float16(402), int16(33)\n",
      "memory usage: 2.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_vect=time.time()\n",
    "\n",
    "#Fit my vectorizer on the entire dataset instead of the training rows\n",
    "#Score improved by .0001\n",
    "vectorizer.fit(df.to_dict('records'))\n",
    "\n",
    "ready_df = vectorizer.transform(df.to_dict('records'))\n",
    "tfvocab = vectorizer.get_feature_names()\n",
    "print(\"Vectorization Runtime: %0.2f Minutes\"%((time.time() - start_vect)/60))\n",
    "\n",
    "# Drop Text Cols\n",
    "textfeats = [\"description\", \"title\"]\n",
    "df.drop(textfeats, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "ridge_params = {'alpha':30.0, 'fit_intercept':True, 'normalize':False, 'copy_X':True,\n",
    "                'max_iter':None, 'tol':0.001, 'solver':'auto', 'random_state':SEED}\n",
    "\n",
    "#Ridge oof method from Faron's kernel\n",
    "#I was using this to analyze my vectorization, but figured it would be interesting to add the results back into the dataset\n",
    "#It doesn't really add much to the score, but it does help lightgbm converge faster\n",
    "ridge = SklearnWrapper(clf=Ridge, seed = SEED, params = ridge_params)\n",
    "ridge_oof_train, ridge_oof_test = get_oof(ridge, ready_df[:ntrain], y, ready_df[ntrain:])\n",
    "\n",
    "rms = sqrt(mean_squared_error(y, ridge_oof_train))\n",
    "print('Ridge OOF RMSE: {}'.format(rms))\n",
    "\n",
    "print(\"Modeling Stage\")\n",
    "\n",
    "ridge_preds = np.concatenate([ridge_oof_train, ridge_oof_test])\n",
    "\n",
    "df['ridge_preds'] = ridge_preds\n",
    "\n",
    "# Combine Dense Features with Sparse Text Bag of Words Features\n",
    "X = hstack([csr_matrix(df.loc[traindex,:].values),ready_df[0:traindex.shape[0]]]) # Sparse Matrix\n",
    "testing = hstack([csr_matrix(df.loc[testdex,:].values),ready_df[traindex.shape[0]:]])\n",
    "tfvocab = df.columns.tolist() + tfvocab\n",
    "for shape in [X,testing]:\n",
    "    print(\"{} Rows and {} Cols\".format(*shape.shape))\n",
    "print(\"Feature Names Length: \",len(tfvocab))\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nModeling Stage\")\n",
    "\n",
    "del ridge_preds,vectorizer\n",
    "gc.collect();\n",
    "    \n",
    "print(\"Light Gradient Boosting Regressor\")\n",
    "lgbm_params =  {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    # 'max_depth': 15,\n",
    "    'num_leaves': 270,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 2,\n",
    "    'learning_rate': 0.016,\n",
    "    'verbose': 0\n",
    "}  \n",
    "\n",
    "\n",
    "if VALID == True:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, test_size=0.10, random_state=23)\n",
    "        \n",
    "    # LGBM Dataset Formatting \n",
    "    lgtrain = lgb.Dataset(X_train, y_train,\n",
    "                    feature_name=tfvocab)\n",
    "    lgvalid = lgb.Dataset(X_valid, y_valid,\n",
    "                    feature_name=tfvocab)\n",
    "    del X, X_train; gc.collect()\n",
    "    \n",
    "    # Go Go Go\n",
    "    lgb_clf = lgb.train(\n",
    "        lgbm_params,\n",
    "        lgtrain,\n",
    "        num_boost_round=20000,\n",
    "        valid_sets=[lgtrain, lgvalid],\n",
    "        valid_names=['train','valid'],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=100\n",
    "    )\n",
    "    print(\"Model Evaluation Stage\")\n",
    "    print('RMSE:', np.sqrt(metrics.mean_squared_error(y_valid, lgb_clf.predict(X_valid))))\n",
    "    del X_valid ; gc.collect()\n",
    "\n",
    "else:\n",
    "    # LGBM Dataset Formatting \n",
    "    lgtrain = lgb.Dataset(X, y,\n",
    "                    feature_name=tfvocab)\n",
    "    del X; gc.collect()\n",
    "    # Go Go Go\n",
    "    lgb_clf = lgb.train(\n",
    "        lgbm_params,\n",
    "        lgtrain,\n",
    "        num_boost_round=1550,\n",
    "        verbose_eval=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lgb_clf, './models/lgbm_1.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Plot\n",
    "f, ax = plt.subplots(figsize=[7,10])\n",
    "lgb.plot_importance(lgb_clf, max_num_features=75, ax=ax)\n",
    "plt.title(\"Light GBM Feature Importance\")\n",
    "plt.savefig('feature_import.png')\n",
    "\n",
    "print(\"Model Evaluation Stage\")\n",
    "lgpred = lgb_clf.predict(testing) \n",
    "\n",
    "#Mixing lightgbm with ridge. I haven't really tested if this improves the score or not\n",
    "#blend = 0.95*lgpred + 0.05*ridge_oof_test[:,0]\n",
    "lgsub = pd.DataFrame(lgpred,columns=[\"deal_probability\"],index=testdex)\n",
    "lgsub['deal_probability'].clip(0.0, 1.0, inplace=True) # Between 0 and 1\n",
    "lgsub.to_csv(\"lgsub.csv\",index=True,header=True)\n",
    "#print(\"Model Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))\n",
    "print(\"Notebook Runtime: %0.2f Minutes\"%((time.time() - notebookstart)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.strftime('%H:%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.time().s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
