{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/cerdgio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from gc import collect\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "PATH = './input/'\n",
    "nrows = None\n",
    "SEED = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cerdgio/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:6201: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2011862, 17)\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_csv('{PATH}train.csv'.format(PATH = PATH), nrows = nrows, index_col='item_id')\n",
    "print(data_train.shape)\n",
    "train_index = data_train.shape[0]\n",
    "data_train = data_train.append(pd.read_csv('{PATH}test.csv'.format(PATH = PATH), \n",
    "                                           nrows = nrows, index_col='item_id'))\n",
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['activation_date'] = pd.to_datetime(data_train['activation_date'])\n",
    "data_train['day'] = data_train['activation_date'].dt.day\n",
    "data_train['weekday'] = data_train['activation_date'].dt.dayofweek\n",
    "data_train['region_city'] = data_train['region']+'_'+data_train['city']\n",
    "data_train['parent_category'] = data_train['parent_category_name']+'_'+data_train['category_name']\n",
    "data_train['logprice'] = np.log(data_train['price']+.000001)\n",
    "data_train['subtarget'] = data_train['deal_probability'].astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['pirce_qbin'] = pd.qcut(data_train['price'], np.linspace(0, 1., 21), duplicates='drop')\n",
    "data_train['pirce_bin'] = pd.cut(data_train['price'], [0, 50, 100, 200, 300, 500, 700, 1000, 2000, \n",
    "                                                       3000, 5000, 7000, 10000, 20000, \n",
    "                                                       30000, 50000, 70000, 100000, 200000, \n",
    "                                                       300000, 500000, 700000, 1000000, np.Inf])\n",
    "data_train['logpirce_qbin'] = pd.qcut(data_train['logprice'], np.linspace(0, 1., 21), duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['item_seq_number_bin'] = pd.cut(data_train['item_seq_number'], [0,1,2,3,4,5,6,7,8,9,10,12,14,16,18,20,25,30,35,40,45,50,\n",
    "                                       60,70,80,90,100,200,300,400,500,600,700,800,900,1000,2000,3000,\n",
    "                                       4000,5000,10000, np.Inf])\n",
    "data_train['item_seq_number_qbin'] = pd.qcut(data_train['item_seq_number'], np.linspace(0, 1., 21), \n",
    "                                             duplicates='drop', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = \\\n",
    "['region','city','region_city','parent_category_name','day', 'weekday', 'user_type','pirce_bin', 'pirce_qbin',\n",
    " 'logpirce_qbin', 'item_seq_number_bin', 'item_seq_number_qbin',\n",
    " 'category_name','parent_category','image_top_1', 'item_seq_number']\n",
    "drop_cols = ['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data_train.columns:\n",
    "    if (data_train[col].dtypes=='object'):\n",
    "        data_train[col].fillna('-999', inplace=True)\n",
    "    elif (data_train[col].dtype.name=='category'):\n",
    "        data_train[col] = data_train[col].astype(str)\n",
    "        data_train[col].fillna(-999, inplace=True)\n",
    "    else:\n",
    "        data_train[col].fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_col(col_names, col):\n",
    "    for i in col_names:\n",
    "        data_train[i+'_'+col] = data_train[i].astype(str).values+'_'+data_train[col].astype(str).values\n",
    "        cat_cols.append(i+'_'+col)\n",
    "\n",
    "add_col(['region','city','region_city','parent_category_name','user_type','pirce_bin', 'pirce_qbin',\n",
    " 'logpirce_qbin', 'item_seq_number_bin', 'item_seq_number_qbin',\n",
    " 'category_name','parent_category','image_top_1', 'item_seq_number'], 'weekday')\n",
    "add_col(['region','city','region_city','parent_category_name','pirce_bin', 'pirce_qbin',\n",
    " 'logpirce_qbin', 'item_seq_number_bin', 'item_seq_number_qbin',\n",
    " 'category_name','parent_category','image_top_1', 'item_seq_number'],'user_type')\n",
    "add_col(['region','city','region_city','pirce_bin', 'pirce_qbin',\n",
    " 'logpirce_qbin', 'item_seq_number_bin', 'item_seq_number_qbin','parent_category','image_top_1', 'item_seq_number'],\n",
    "        'category_name')\n",
    "add_col(['pirce_bin', 'pirce_qbin',\n",
    " 'logpirce_qbin', 'item_seq_number_bin', 'item_seq_number_qbin',\n",
    "         'item_seq_number'],\n",
    "        'city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import TargetEncoding\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TargetEncoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(508438, 71)\n",
      "(1503424, 72)\n"
     ]
    }
   ],
   "source": [
    "data_test = data_train[train_index:].copy()\n",
    "data_test.drop(['deal_probability'], axis = 1, inplace=True)\n",
    "print(data_test.shape)\n",
    "data_train = data_train[:train_index].copy()\n",
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n",
    "y = data_train['subtarget']\n",
    "for train_index, test_index in skf.split(data_train, y):\n",
    "    X_train, X_test = data_train.iloc[train_index], data_train.iloc[test_index]\n",
    "    y_train, _ = y[train_index], y[test_index]\n",
    "    for col in cat_cols:\n",
    "        if col+'_te_bin' in data_train.columns:\n",
    "            pass\n",
    "        else:\n",
    "            data_train[col+'_te_bin'] = 999\n",
    "        te.fit(X_train[col], y_train)\n",
    "        #print(te.transform(X_test[col]).shape, X_test[col].shape, test_index.shape, train_index.shape)\n",
    "        data_train.loc[data_train.index[test_index], col+'_te_bin'] = te.transform(X_test[col])\n",
    "        \n",
    "        if col+'_te' in data_train.columns:\n",
    "            pass\n",
    "        else:\n",
    "            data_train[col+'_te'] = 999\n",
    "        te.fit(X_train[col], data_train.loc[data_train.index[train_index], 'deal_probability'])\n",
    "        #print(te.transform(X_test[col]).shape, X_test[col].shape, test_index.shape, train_index.shape)\n",
    "        data_train.loc[data_train.index[test_index], col+'_te'] = te.transform(X_test[col])\n",
    "################## alpha 200    \n",
    "        if col+'_te_bin' in data_train.columns:\n",
    "            pass\n",
    "        else:\n",
    "            data_train[col+'_te_bin_200'] = 999\n",
    "        te.fit(X_train[col], y_train, alpha=200)\n",
    "        #print(te.transform(X_test[col]).shape, X_test[col].shape, test_index.shape, train_index.shape)\n",
    "        data_train.loc[data_train.index[test_index], col+'_te_bin_200'] = te.transform(X_test[col])\n",
    "        \n",
    "        if col+'_te' in data_train.columns:\n",
    "            pass\n",
    "        else:\n",
    "            data_train[col+'_te_200'] = 999\n",
    "        te.fit(X_train[col], data_train.loc[data_train.index[train_index], 'deal_probability'], alpha=200)\n",
    "        #print(te.transform(X_test[col]).shape, X_test[col].shape, test_index.shape, train_index.shape)\n",
    "        data_train.loc[data_train.index[test_index], col+'_te_200'] = te.transform(X_test[col])\n",
    "################## alpha 1000        \n",
    "        if col+'_te_bin' in data_train.columns:\n",
    "            pass\n",
    "        else:\n",
    "            data_train[col+'_te_bin_100'] = 999\n",
    "        te.fit(X_train[col], y_train, alpha = 1000)\n",
    "        #print(te.transform(X_test[col]).shape, X_test[col].shape, test_index.shape, train_index.shape)\n",
    "        data_train.loc[data_train.index[test_index], col+'_te_bin_100'] = te.transform(X_test[col])\n",
    "        \n",
    "        if col+'_te' in data_train.columns:\n",
    "            pass\n",
    "        else:\n",
    "            data_train[col+'_te_100'] = 999\n",
    "        te.fit(X_train[col], data_train.loc[data_train.index[train_index], 'deal_probability'], alpha = 1000)\n",
    "        #print(te.transform(X_test[col]).shape, X_test[col].shape, test_index.shape, train_index.shape)\n",
    "        data_train.loc[data_train.index[test_index], col+'_te_100'] = te.transform(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    \n",
    "        te.fit(data_train.loc[:,col],  data_train['subtarget'])\n",
    "        #print(te.transform(X_test[col]).shape, X_test[col].shape, test_index.shape, train_index.shape)\n",
    "        data_test[col+'_te_bin'] = te.transform(data_test[col])\n",
    "    \n",
    "        te.fit(data_train.loc[:,col], data_train['deal_probability'])\n",
    "        #print(te.transform(X_test[col]).shape, X_test[col].shape, test_index.shape, train_index.shape)\n",
    "        data_test[col+'_te'] = te.transform(data_test[col])\n",
    "################## alpha 200    \n",
    "\n",
    "        te.fit(data_train.loc[:,col],  data_train['subtarget'], alpha=200)\n",
    "        #print(te.transform(X_test[col]).shape, X_test[col].shape, test_index.shape, train_index.shape)\n",
    "        data_test[col+'_te_bin_200'] = te.transform(data_test[col])\n",
    "        \n",
    "        te.fit(data_train.loc[:,col], data_train['deal_probability'], alpha=200)\n",
    "        #print(te.transform(X_test[col]).shape, X_test[col].shape, test_index.shape, train_index.shape)\n",
    "        data_test[col+'_te_200'] = te.transform(data_test[col])\n",
    "################## alpha 1000        \n",
    "\n",
    "        te.fit(data_train.loc[:,col],  data_train['subtarget'], alpha = 1000)\n",
    "        #print(te.transform(X_test[col]).shape, X_test[col].shape, test_index.shape, train_index.shape)\n",
    "        data_test[col+'_te_bin_100'] = te.transform(data_test[col])\n",
    "        \n",
    "        te.fit(data_train.loc[:,col], data_train['deal_probability'], alpha = 1000)\n",
    "        #print(te.transform(X_test[col]).shape, X_test[col].shape, test_index.shape, train_index.shape)\n",
    "        data_test[col+'_te_100'] = te.transform(data_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfeats = [\"description\", \"title\", \"param_1\"]\n",
    "\n",
    "def creat_str_features(merge, textfeats):\n",
    "    from nltk.corpus import stopwords\n",
    "    import string\n",
    "    stopwords_en = {x: 1 for x in stopwords.words('english')}\n",
    "    stopwords = {x: 1 for x in stopwords.words('russian')}\n",
    "    non_alphanums = re.compile(u'[^A-Za-z0-9]+')\n",
    "    non_alphanumpunct = re.compile(u'[^A-Za-z0-9\\.?!,; \\(\\)\\[\\]\\'\\\"\\$]+')\n",
    "    RE_PUNCTUATION = '|'.join([re.escape(x) for x in string.punctuation])\n",
    "    \n",
    "    def sum_numbers(desc):\n",
    "        if not isinstance(desc, str):\n",
    "            return 0\n",
    "        try:\n",
    "            return sum([to_number(s) for s in desc.split()])\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    for cols in textfeats:\n",
    "        merge[cols] = merge[cols].astype(str) \n",
    "        merge[cols] = merge[cols].astype(str).fillna('missing') # FILL NA\n",
    "        merge[cols] = merge[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently\n",
    "        merge[cols + '_num_stopwords'] = merge[cols].apply(lambda x: len([w for w in x.split() if w in stopwords])) # Count number of Stopwords\n",
    "        merge[cols + '_num_stopwords_en'] = merge[cols].apply(lambda x: len([w for w in x.split() if w in stopwords_en])) # Count number of Stopwords\n",
    "        merge[cols + '_num_punctuations'] = merge[cols].apply(lambda comment: (comment.count(RE_PUNCTUATION))) # Count number of Punctuations\n",
    "        merge[cols + '_num_alphabets'] = merge[cols].apply(lambda comment: (comment.count(r'[a-zA-Z]'))) # Count number of Alphabets\n",
    "        merge[cols + '_num_alphanumeric'] = merge[cols].apply(lambda comment: (comment.count(r'[A-Za-z0-9]'))) # Count number of AlphaNumeric\n",
    "        merge[cols + '_num_digits'] = merge[cols].apply(lambda comment: (comment.count('[0-9]'))) # Count number of Digits\n",
    "        merge[cols + '_num_letters'] = merge[cols].apply(lambda comment: len(comment)) # Count number of Letters\n",
    "        merge[cols + '_num_words'] = merge[cols].apply(lambda comment: len(comment.split())) # Count number of Words\n",
    "        merge[cols + '_num_unique_words'] = merge[cols].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "        merge[cols + '_words_vs_unique'] = merge[cols+'_num_unique_words'] / merge[cols+'_num_words'] # Count Unique Words\n",
    "        merge[cols + '_letters_per_word'] = merge[cols+'_num_letters'] / merge[cols+'_num_words'] # Letters per Word\n",
    "        merge[cols + '_punctuations_by_letters'] = merge[cols+'_num_punctuations'] / merge[cols+'_num_letters'] # Punctuations by Letters\n",
    "        merge[cols + '_punctuations_by_words'] = merge[cols+'_num_punctuations'] / merge[cols+'_num_words'] # Punctuations by Words\n",
    "        merge[cols + '_digits_by_letters'] = merge[cols+'_num_digits'] / merge[cols+'_num_letters'] # Digits by Letters\n",
    "        merge[cols + '_alphanumeric_by_letters'] = merge[cols+'_num_alphanumeric'] / merge[cols+'_num_letters'] # AlphaNumeric by Letters\n",
    "        merge[cols + '_alphabets_by_letters'] = merge[cols+'_num_alphabets'] / merge[cols+'_num_letters'] # Alphabets by Letters\n",
    "        merge[cols + '_stopwords_by_letters'] = merge[cols+'_num_stopwords'] / merge[cols+'_num_letters'] # Stopwords by Letters\n",
    "        merge[cols + '_stopwords_by_words'] = merge[cols+'_num_stopwords'] / merge[cols+'_num_words'] # Stopwords by Letters\n",
    "        merge[cols + '_stopwords_by_letters_en'] = merge[cols+'_num_stopwords_en'] / merge[cols+'_num_letters'] # Stopwords by Letters\n",
    "        merge[cols + '_stopwords_by_words_en'] = merge[cols+'_num_stopwords_en'] / merge[cols+'_num_words'] # Stopwords by Letters    \n",
    "        merge[cols + '_mean'] = merge[cols].apply(lambda x: 0 if len(x) == 0 else float(len(x.split())) / len(x)) * 10 # Mean\n",
    "        merge[cols + '_num_sum'] = merge[cols].apply(sum_numbers) \n",
    "\n",
    "    # Extra Feature Engineering\n",
    "    merge['title_desc_len_ratio'] = merge['title_num_letters']/merge['description_num_letters']\n",
    "    merge['title_param1_len_ratio'] = merge['title_num_letters']/merge['param_1_num_letters']\n",
    "    merge['param_1_copy_desc_len_ratio'] = merge['param_1_num_letters']/merge['description_num_letters']\n",
    "    \n",
    "    return merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = creat_str_features(data_train, textfeats)\n",
    "data_test = creat_str_features(data_test, textfeats)\n",
    "data_train.drop(drop_cols, axis=1, inplace=True)\n",
    "data_test.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deal_probability</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>price</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>logprice</th>\n",
       "      <th>region_te_bin</th>\n",
       "      <th>region_te</th>\n",
       "      <th>region_te_bin_200</th>\n",
       "      <th>...</th>\n",
       "      <th>param_1_alphabets_by_letters</th>\n",
       "      <th>param_1_stopwords_by_letters</th>\n",
       "      <th>param_1_stopwords_by_words</th>\n",
       "      <th>param_1_stopwords_by_letters_en</th>\n",
       "      <th>param_1_stopwords_by_words_en</th>\n",
       "      <th>param_1_mean</th>\n",
       "      <th>param_1_num_sum</th>\n",
       "      <th>title_desc_len_ratio</th>\n",
       "      <th>title_param1_len_ratio</th>\n",
       "      <th>param_1_copy_desc_len_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.503424e+06</td>\n",
       "      <td>1.503424e+06</td>\n",
       "      <td>1.503424e+06</td>\n",
       "      <td>1.503424e+06</td>\n",
       "      <td>1.503424e+06</td>\n",
       "      <td>1.503424e+06</td>\n",
       "      <td>1.503424e+06</td>\n",
       "      <td>1.503424e+06</td>\n",
       "      <td>1.503424e+06</td>\n",
       "      <td>1.503424e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1503424.0</td>\n",
       "      <td>1.503424e+06</td>\n",
       "      <td>1.503424e+06</td>\n",
       "      <td>1503424.0</td>\n",
       "      <td>1503424.0</td>\n",
       "      <td>1.503424e+06</td>\n",
       "      <td>1503424.0</td>\n",
       "      <td>1.503424e+06</td>\n",
       "      <td>1.503424e+06</td>\n",
       "      <td>1.503424e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.391306e-01</td>\n",
       "      <td>1.074114e+03</td>\n",
       "      <td>7.436740e+02</td>\n",
       "      <td>2.986692e+05</td>\n",
       "      <td>2.155644e+01</td>\n",
       "      <td>2.942614e+00</td>\n",
       "      <td>-4.935659e+01</td>\n",
       "      <td>3.517341e-01</td>\n",
       "      <td>1.391304e-01</td>\n",
       "      <td>3.517442e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.705155e-02</td>\n",
       "      <td>1.527001e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.582316e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.564701e-01</td>\n",
       "      <td>2.294522e+00</td>\n",
       "      <td>4.475241e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.600785e-01</td>\n",
       "      <td>1.104164e+03</td>\n",
       "      <td>5.572522e+03</td>\n",
       "      <td>6.496484e+07</td>\n",
       "      <td>4.045831e+00</td>\n",
       "      <td>2.031382e+00</td>\n",
       "      <td>2.330120e+02</td>\n",
       "      <td>3.512749e-02</td>\n",
       "      <td>9.269730e-03</td>\n",
       "      <td>3.495678e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.926823e-02</td>\n",
       "      <td>2.176477e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.329003e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.536704e+00</td>\n",
       "      <td>1.878767e+00</td>\n",
       "      <td>9.408213e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>2.927366e-01</td>\n",
       "      <td>1.199856e-01</td>\n",
       "      <td>2.929241e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.250000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.730782e-04</td>\n",
       "      <td>3.448276e-02</td>\n",
       "      <td>8.382230e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.250000e+02</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>4.000000e+02</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.991465e+00</td>\n",
       "      <td>3.391020e-01</td>\n",
       "      <td>1.343862e-01</td>\n",
       "      <td>3.391534e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.428571e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.128205e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.600000e+02</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.907755e+00</td>\n",
       "      <td>3.508611e-01</td>\n",
       "      <td>1.425650e-01</td>\n",
       "      <td>3.508644e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.538462e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.040816e-01</td>\n",
       "      <td>1.700000e+00</td>\n",
       "      <td>1.320755e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.508700e-01</td>\n",
       "      <td>2.078000e+03</td>\n",
       "      <td>8.800000e+01</td>\n",
       "      <td>6.000000e+03</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>8.699515e+00</td>\n",
       "      <td>3.705866e-01</td>\n",
       "      <td>1.462397e-01</td>\n",
       "      <td>3.704588e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.142857e-02</td>\n",
       "      <td>3.333333e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.818182e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.375000e-01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.076923e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.066000e+03</td>\n",
       "      <td>2.044290e+05</td>\n",
       "      <td>7.950101e+10</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.509904e+01</td>\n",
       "      <td>4.241756e-01</td>\n",
       "      <td>1.562561e-01</td>\n",
       "      <td>4.236287e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.250000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>2.900000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 436 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       deal_probability   image_top_1  item_seq_number         price  \\\n",
       "count      1.503424e+06  1.503424e+06     1.503424e+06  1.503424e+06   \n",
       "mean       1.391306e-01  1.074114e+03     7.436740e+02  2.986692e+05   \n",
       "std        2.600785e-01  1.104164e+03     5.572522e+03  6.496484e+07   \n",
       "min        0.000000e+00 -9.990000e+02     1.000000e+00 -9.990000e+02   \n",
       "25%        0.000000e+00  1.250000e+02     9.000000e+00  4.000000e+02   \n",
       "50%        0.000000e+00  9.600000e+02     2.900000e+01  1.000000e+03   \n",
       "75%        1.508700e-01  2.078000e+03     8.800000e+01  6.000000e+03   \n",
       "max        1.000000e+00  3.066000e+03     2.044290e+05  7.950101e+10   \n",
       "\n",
       "                day       weekday      logprice  region_te_bin     region_te  \\\n",
       "count  1.503424e+06  1.503424e+06  1.503424e+06   1.503424e+06  1.503424e+06   \n",
       "mean   2.155644e+01  2.942614e+00 -4.935659e+01   3.517341e-01  1.391304e-01   \n",
       "std    4.045831e+00  2.031382e+00  2.330120e+02   3.512749e-02  9.269730e-03   \n",
       "min    1.000000e+00  0.000000e+00 -9.990000e+02   2.927366e-01  1.199856e-01   \n",
       "25%    1.800000e+01  1.000000e+00  5.991465e+00   3.391020e-01  1.343862e-01   \n",
       "50%    2.200000e+01  3.000000e+00  6.907755e+00   3.508611e-01  1.425650e-01   \n",
       "75%    2.500000e+01  5.000000e+00  8.699515e+00   3.705866e-01  1.462397e-01   \n",
       "max    3.100000e+01  6.000000e+00  2.509904e+01   4.241756e-01  1.562561e-01   \n",
       "\n",
       "       region_te_bin_200             ...               \\\n",
       "count       1.503424e+06             ...                \n",
       "mean        3.517442e-01             ...                \n",
       "std         3.495678e-02             ...                \n",
       "min         2.929241e-01             ...                \n",
       "25%         3.391534e-01             ...                \n",
       "50%         3.508644e-01             ...                \n",
       "75%         3.704588e-01             ...                \n",
       "max         4.236287e-01             ...                \n",
       "\n",
       "       param_1_alphabets_by_letters  param_1_stopwords_by_letters  \\\n",
       "count                     1503424.0                  1.503424e+06   \n",
       "mean                            0.0                  2.705155e-02   \n",
       "std                             0.0                  3.926823e-02   \n",
       "min                             0.0                  0.000000e+00   \n",
       "25%                             0.0                  0.000000e+00   \n",
       "50%                             0.0                  0.000000e+00   \n",
       "75%                             0.0                  7.142857e-02   \n",
       "max                             0.0                  1.250000e-01   \n",
       "\n",
       "       param_1_stopwords_by_words  param_1_stopwords_by_letters_en  \\\n",
       "count                1.503424e+06                        1503424.0   \n",
       "mean                 1.527001e-01                              0.0   \n",
       "std                  2.176477e-01                              0.0   \n",
       "min                  0.000000e+00                              0.0   \n",
       "25%                  0.000000e+00                              0.0   \n",
       "50%                  0.000000e+00                              0.0   \n",
       "75%                  3.333333e-01                              0.0   \n",
       "max                  5.000000e-01                              0.0   \n",
       "\n",
       "       param_1_stopwords_by_words_en  param_1_mean  param_1_num_sum  \\\n",
       "count                      1503424.0  1.503424e+06        1503424.0   \n",
       "mean                             0.0  1.582316e+00              0.0   \n",
       "std                              0.0  4.329003e-01              0.0   \n",
       "min                              0.0  6.250000e-01              0.0   \n",
       "25%                              0.0  1.428571e+00              0.0   \n",
       "50%                              0.0  1.538462e+00              0.0   \n",
       "75%                              0.0  1.818182e+00              0.0   \n",
       "max                              0.0  5.000000e+00              0.0   \n",
       "\n",
       "       title_desc_len_ratio  title_param1_len_ratio  \\\n",
       "count          1.503424e+06            1.503424e+06   \n",
       "mean           6.564701e-01            2.294522e+00   \n",
       "std            1.536704e+00            1.878767e+00   \n",
       "min            9.730782e-04            3.448276e-02   \n",
       "25%            1.000000e-01            1.000000e+00   \n",
       "50%            2.040816e-01            1.700000e+00   \n",
       "75%            4.375000e-01            3.000000e+00   \n",
       "max            5.000000e+01            2.500000e+01   \n",
       "\n",
       "       param_1_copy_desc_len_ratio  \n",
       "count                 1.503424e+06  \n",
       "mean                  4.475241e-01  \n",
       "std                   9.408213e-01  \n",
       "min                   8.382230e-04  \n",
       "25%                   5.128205e-02  \n",
       "50%                   1.320755e-01  \n",
       "75%                   3.076923e-01  \n",
       "max                   2.900000e+01  \n",
       "\n",
       "[8 rows x 436 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>price</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>logprice</th>\n",
       "      <th>region_te_bin</th>\n",
       "      <th>region_te</th>\n",
       "      <th>region_te_bin_200</th>\n",
       "      <th>region_te_200</th>\n",
       "      <th>...</th>\n",
       "      <th>param_1_alphabets_by_letters</th>\n",
       "      <th>param_1_stopwords_by_letters</th>\n",
       "      <th>param_1_stopwords_by_words</th>\n",
       "      <th>param_1_stopwords_by_letters_en</th>\n",
       "      <th>param_1_stopwords_by_words_en</th>\n",
       "      <th>param_1_mean</th>\n",
       "      <th>param_1_num_sum</th>\n",
       "      <th>title_desc_len_ratio</th>\n",
       "      <th>title_param1_len_ratio</th>\n",
       "      <th>param_1_copy_desc_len_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>508438.000000</td>\n",
       "      <td>508438.000000</td>\n",
       "      <td>5.084380e+05</td>\n",
       "      <td>508438.000000</td>\n",
       "      <td>508438.000000</td>\n",
       "      <td>508438.000000</td>\n",
       "      <td>508438.000000</td>\n",
       "      <td>508438.000000</td>\n",
       "      <td>508438.000000</td>\n",
       "      <td>508438.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>508438.0</td>\n",
       "      <td>508438.000000</td>\n",
       "      <td>508438.000000</td>\n",
       "      <td>508438.0</td>\n",
       "      <td>508438.0</td>\n",
       "      <td>508438.000000</td>\n",
       "      <td>508438.0</td>\n",
       "      <td>508438.000000</td>\n",
       "      <td>508438.000000</td>\n",
       "      <td>508438.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1105.465481</td>\n",
       "      <td>825.132150</td>\n",
       "      <td>2.629264e+05</td>\n",
       "      <td>14.985650</td>\n",
       "      <td>2.763963</td>\n",
       "      <td>-52.661586</td>\n",
       "      <td>0.351119</td>\n",
       "      <td>0.139072</td>\n",
       "      <td>0.351126</td>\n",
       "      <td>0.139072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026136</td>\n",
       "      <td>0.146968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.585041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.320509</td>\n",
       "      <td>2.361140</td>\n",
       "      <td>0.220038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1118.632459</td>\n",
       "      <td>5646.868618</td>\n",
       "      <td>5.200803e+06</td>\n",
       "      <td>2.092457</td>\n",
       "      <td>1.951071</td>\n",
       "      <td>239.435197</td>\n",
       "      <td>0.034839</td>\n",
       "      <td>0.009297</td>\n",
       "      <td>0.034726</td>\n",
       "      <td>0.009262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038883</td>\n",
       "      <td>0.214309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.442198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.572874</td>\n",
       "      <td>1.928929</td>\n",
       "      <td>0.396500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.294829</td>\n",
       "      <td>0.120357</td>\n",
       "      <td>0.294950</td>\n",
       "      <td>0.120427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>231.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000e+02</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.991465</td>\n",
       "      <td>0.339341</td>\n",
       "      <td>0.135480</td>\n",
       "      <td>0.339375</td>\n",
       "      <td>0.135496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>1.041667</td>\n",
       "      <td>0.046053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1046.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.200000e+03</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.090077</td>\n",
       "      <td>0.347971</td>\n",
       "      <td>0.142602</td>\n",
       "      <td>0.347992</td>\n",
       "      <td>0.142593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.117117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2188.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>7.500000e+03</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.922658</td>\n",
       "      <td>0.364654</td>\n",
       "      <td>0.146608</td>\n",
       "      <td>0.364625</td>\n",
       "      <td>0.146587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3066.000000</td>\n",
       "      <td>205064.000000</td>\n",
       "      <td>3.000060e+09</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>21.821898</td>\n",
       "      <td>0.422564</td>\n",
       "      <td>0.155921</td>\n",
       "      <td>0.422204</td>\n",
       "      <td>0.155807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 435 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_top_1  item_seq_number         price            day  \\\n",
       "count  508438.000000    508438.000000  5.084380e+05  508438.000000   \n",
       "mean     1105.465481       825.132150  2.629264e+05      14.985650   \n",
       "std      1118.632459      5646.868618  5.200803e+06       2.092457   \n",
       "min      -999.000000         1.000000 -9.990000e+02      12.000000   \n",
       "25%       231.000000         8.000000  4.000000e+02      13.000000   \n",
       "50%      1046.000000        30.000000  1.200000e+03      15.000000   \n",
       "75%      2188.000000        94.000000  7.500000e+03      17.000000   \n",
       "max      3066.000000    205064.000000  3.000060e+09      20.000000   \n",
       "\n",
       "             weekday       logprice  region_te_bin      region_te  \\\n",
       "count  508438.000000  508438.000000  508438.000000  508438.000000   \n",
       "mean        2.763963     -52.661586       0.351119       0.139072   \n",
       "std         1.951071     239.435197       0.034839       0.009297   \n",
       "min         0.000000    -999.000000       0.294829       0.120357   \n",
       "25%         1.000000       5.991465       0.339341       0.135480   \n",
       "50%         3.000000       7.090077       0.347971       0.142602   \n",
       "75%         4.000000       8.922658       0.364654       0.146608   \n",
       "max         6.000000      21.821898       0.422564       0.155921   \n",
       "\n",
       "       region_te_bin_200  region_te_200             ...               \\\n",
       "count      508438.000000  508438.000000             ...                \n",
       "mean            0.351126       0.139072             ...                \n",
       "std             0.034726       0.009262             ...                \n",
       "min             0.294950       0.120427             ...                \n",
       "25%             0.339375       0.135496             ...                \n",
       "50%             0.347992       0.142593             ...                \n",
       "75%             0.364625       0.146587             ...                \n",
       "max             0.422204       0.155807             ...                \n",
       "\n",
       "       param_1_alphabets_by_letters  param_1_stopwords_by_letters  \\\n",
       "count                      508438.0                 508438.000000   \n",
       "mean                            0.0                      0.026136   \n",
       "std                             0.0                      0.038883   \n",
       "min                             0.0                      0.000000   \n",
       "25%                             0.0                      0.000000   \n",
       "50%                             0.0                      0.000000   \n",
       "75%                             0.0                      0.062500   \n",
       "max                             0.0                      0.125000   \n",
       "\n",
       "       param_1_stopwords_by_words  param_1_stopwords_by_letters_en  \\\n",
       "count               508438.000000                         508438.0   \n",
       "mean                     0.146968                              0.0   \n",
       "std                      0.214309                              0.0   \n",
       "min                      0.000000                              0.0   \n",
       "25%                      0.000000                              0.0   \n",
       "50%                      0.000000                              0.0   \n",
       "75%                      0.333333                              0.0   \n",
       "max                      0.500000                              0.0   \n",
       "\n",
       "       param_1_stopwords_by_words_en   param_1_mean  param_1_num_sum  \\\n",
       "count                       508438.0  508438.000000         508438.0   \n",
       "mean                             0.0       1.585041              0.0   \n",
       "std                              0.0       0.442198              0.0   \n",
       "min                              0.0       0.625000              0.0   \n",
       "25%                              0.0       1.428571              0.0   \n",
       "50%                              0.0       1.538462              0.0   \n",
       "75%                              0.0       1.818182              0.0   \n",
       "max                              0.0       5.000000              0.0   \n",
       "\n",
       "       title_desc_len_ratio  title_param1_len_ratio  \\\n",
       "count         508438.000000           508438.000000   \n",
       "mean               0.320509                2.361140   \n",
       "std                0.572874                1.928929   \n",
       "min                0.001683                0.071429   \n",
       "25%                0.093750                1.041667   \n",
       "50%                0.184211                1.750000   \n",
       "75%                0.357143                3.142857   \n",
       "max               48.000000               25.000000   \n",
       "\n",
       "       param_1_copy_desc_len_ratio  \n",
       "count                508438.000000  \n",
       "mean                      0.220038  \n",
       "std                       0.396500  \n",
       "min                       0.000651  \n",
       "25%                       0.046053  \n",
       "50%                       0.117117  \n",
       "75%                       0.250000  \n",
       "max                      25.000000  \n",
       "\n",
       "[8 rows x 435 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv(f'{PATH}train_features.csv')\n",
    "data_test.to_csv(f'{PATH}test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03:06'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.strftime('%H:%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
